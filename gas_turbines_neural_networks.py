# -*- coding: utf-8 -*-
"""gas_turbines_Neural_Networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wv3uKVDRm6UWVJKb5yn7n6fBecDOUXHv
"""

from google.colab import files
uploaded=files.upload()

# Importing the data
import pandas as pd
df=pd.read_csv("gas_turbines.csv")
df.head()

# Get information of the dataset
df.info()
print('The shape of our data is:', df.shape)
df.isnull().any()
df.dtypes

"""**Data Visvualization & EDA (Exploratory Data Analysis)**"""

# let's scatter plot to visualise the attributes all at once
import seaborn as sns
sns.pairplot(data = df, hue = 'TEY')

# Boxplot
df.boxplot(column="TEY", vert=False)

# Histogram
df["TEY"].hist()

# Bar graph
df.plot(kind="bar")

# HeatMap
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['figure.figsize']=(12,6)
sns.heatmap(df.isna(), cmap =('gist_heat'), yticklabels=False)

df.corr()

# Split the input as X and Y variables
X = df.drop(['TEY'], axis=1) # Independent Variable
Y = df['TEY']   # Target Variable

# Import the libraries
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential

# Model fitting
model=Sequential()
model.add(Dense(15, input_dim=10, activation ='relu')) #input layer 15 = 10*1.5 as Neurons we are adding #hidden layer 1
model.add(Dense(23, activation ='relu')) #i can add another hidden layer for the data to improve our underfit or overfit,#hidden layer 2
model.add(Dense(1,activation ="linear"))

model.compile(loss="mse", optimizer='adam', metrics=['mse'])

history=model.fit(X,Y, validation_split=0.3, epochs=150, batch_size=10)

scores=model.evaluate(X,Y)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

history.history.keys()

# Summarize history for accuracy
import matplotlib.pyplot as plt
plt.plot(history.history['mse'])
plt.plot(history.history['val_mse'])
plt.title('model accuracy')
plt.ylabel('MeanSquaredError')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()